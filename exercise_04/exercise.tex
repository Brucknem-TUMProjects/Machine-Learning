%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../Ressources/Preamble.tex} % !!! DON'T TOUCH !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\ExerciseNumber}{04}

\newcommand{\PersonOne}{Marcel Bruckner (03674122)}
\newcommand{\PersonTwo}{Julian Hohenadel (03673879)}
\newcommand{\PersonThree}{Kevin Bein (03707775)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOKUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../Ressources/Cover.tex} % !!! DON'T TOUCH !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% !!! HOMEWORK STARTS HERE !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\Topic{Least squares regression}
%
\Problem{1}
%
\begin{flushleft}
Using $T = diag(t_i)$, the derivative can be calculated similar to the lecture:
\end{flushleft}
\begin{align*}
  \nabla_w E_\text{weighted}(w) &= \nabla_w \frac{1}{2} \sum_{i=1}^N t_i \left[w^T \phi(x_i) - y_i\right]^2 \\
  &= \nabla_w \frac{1}{2} (\Phi w - y)^T T (\Phi w - y) \\
  &= \nabla_w \frac{1}{2} (w^T \Phi^T - y^T)(T\Phi w - T y) \\
  &= \nabla_w \frac{1}{2} (w^T \Phi^T T \Phi w - 2w^T \Phi^T T y + y^T T y) \\
  &= \nabla_w (\frac{1}{2} w^T \Phi^T T \Phi w - w^T \Phi^T T y + \frac{1}{2}y^T T y) \\
  &= \Phi^T T \Phi w - \Phi^T T y \\
  &\overset{!}{=} 0
  & \\
  &\Rightarrow \Phi^T T y = \Phi^T T \Phi w \\
  &\Rightarrow w = \Phi^T T y (\Phi^T T \Phi)^{-1} 
\end{align*}
%
\textit{Missing explanation for 1) and 2)}
%
%
\Topic{Ridge regression}
%
\Problem{2}
%
\begin{align*}
  E_\text{LS} &= \frac{1}{2} \sum_{i=1}^N \left[w^T \phi(x_i) - y_i\right]^2 \\
  &= \frac{1}{2} (\Phi w - y)^T (\Phi w - y) \\
  E_\text{ridge} &= \frac{1}{2} \sum_{i=1}^N \left[w^T \phi(x_i) - y_i\right]^2 + \frac{\lambda}{2} ||w||_2^2 \\
  &= \frac{1}{2} (\Phi w - y)^T (\Phi w - y) + \frac{\lambda}{2} ||w||_2^2 
\end{align*}
\begin{flushleft}
Following the instructions, we can augment the design matrix $\Phi$ and $y$:
\end{flushleft}
\begin{align*}
\Phi &= 
\begin{pmatrix}
  \phi_1(x_1) & \ldots & \phi_M(x_1) \\
  \vdots & \ddots & \vdots \\
  \phi_1(x_N) & \ldots & \phi_M(x_N)
\end{pmatrix} \in \mathbb{R}^{N \times M} \\
\Rightarrow \Phi_A &=
\begin{pmatrix}
  \phi_1(x_1) & \ldots & \phi_M(x_1) \\
  \vdots & \ddots & \vdots \\
  \phi_1(x_N) & \ldots & \phi_M(x_N) \\
  \sqrt{\lambda} I & & 0 \\
  & \ddots & \\
  0 & & \sqrt{\lambda} I
\end{pmatrix} =
\begin{pmatrix} \Phi \\ \sqrt{\lambda} I \end{pmatrix}
\in \mathbb{R}^{N \times M+M} 
\end{align*}
\begin{align*}
  y &= \begin{pmatrix} y_1 \\ \vdots \\ y_M \end{pmatrix}
  \in \mathbb{R}^M 
  \Rightarrow y_A = \begin{pmatrix} y_1 \\ \vdots \\ y_M \\ 0_1 \\ \vdots \\ 0_M \end{pmatrix}
  = \begin{pmatrix} y \\ 0 \end{pmatrix}
\in \mathbb{R}^{M+M}
\end{align*}
\begin{flushleft}
Inserting $\Phi_A$ and $y_A$ into $E_\text{LS}(w)$ directly gives ridge regression:
\begin{align*}
  E_\text{LS}(w) &= \frac{1}{2} (\Phi_A w - y_A)^T (\Phi_A w - y_A) = \frac{1}{2} (\Phi w - y)^T (\Phi w - y) + \frac{\lambda}{2} ||w||_2^2 = E_\text{ridge}(w) \\
\end{align*}
\end{flushleft}
%
\newpage
\Problem{3}
%
\begin{align*}
\nabla_w E_\text{ridge}(w) &= \nabla_w \left[\frac{1}{2} (\Phi w - y)^T (\Phi w - y) + \frac{\lambda}{2} ||w||^2_2 \right] \\
&= \nabla_w \frac{1}{2} (\Phi w - y)^T (\Phi w - y) + \nabla_w \frac{\lambda}{2} ||w||^2_2 \\
&= (\Phi^T \Phi w - \Phi^T y) + \lambda w \\
&\overset{!}{=} 0 \\
&\Rightarrow \Phi^T\Phi w - \Phi^T y + \lambda w = 0 \\
&\Rightarrow \Phi^T\Phi w  + \lambda w = \Phi^T y \\
&\Rightarrow (\Phi^T \Phi + \lambda I) w = \Phi^T y \\
&\Rightarrow w = (\Phi^T \Phi + \lambda I)^{-1} \Phi^T y
\end{align*}
\begin{flushleft}
  When $N < M$ then the covariance Matrix $\Phi^T \Phi$ becomes singular ($det(\Phi^T\Phi) = 0)$ and thus cannot be inverted anymore. Adding the L2-Regularization term in ridge regression $\Phi^T \Phi + \lambda I$ fixes this problem and the inverse can be computed again. L2 also increases the numerical stability by reducing the variance of the matrix and thus roundoff errors cannot accumulate as fast.
\end{flushleft}
%
\Topic{Multi-output linear regression}
%
\Problem{4}
%
\begin{flushleft}
The solution is very similar to the single target case which is given in the lecture:
\end{flushleft}
\[ w_\text{ML} = (\Phi^T \Phi)^{-1} \Phi^T \mathbf{y} = \Phi^\dagger \mathbf{y} \]
For multiple outputs we can combine the weights $\mathbf{w}_i$ and the outputs $\mathbf{y}_i$ into matrices with $n$ rows containing the respective $m^\text{th}$ vector. 
\[ \mathbf{Y} = \begin{pmatrix}y_1 \\ \ldots \\ y_m \end{pmatrix} \in \mathbb{R}^{n\times m} \]
\[ \mathbf{W} = \begin{pmatrix}w_1 \\ \ldots \\ w_m \end{pmatrix} \in \mathbb{R}^{n\times m} \]
The log-likelihood then looks similar to the single output case:
\begin{align*}
- \ln p(\mathbf{Y} | \mathbf{X}, \mathbf{W}, \beta) &= - \ln \left[ \prod_{i=1}^n \mathcal{N}(\mathbf{y}_i | \mathbf{W}^T \phi(\mathbf{x}_i), \beta^{-1} I) \right] \\
&= \frac{\beta}{2} \sum_{i=1}^n (\mathbf{W}^T \phi(\mathbf{x}_i) - \mathbf{Y})^2 - \frac{n}{2} \ln \beta + \frac{n}{2} \ln 2 \pi \\
&= \frac{\beta}{2} \sum_{i=1}^n \left(\sum_{j=1}^m (\mathbf{w}_j^T \phi(\mathbf{x}_i) - \mathbf{y}_{j})^2\right) - \frac{n}{2} \ln \beta + \frac{n}{2} \ln 2 \pi \\
\end{align*}
When calculating the minimzer, the constant parts fall out and we are left with the sum of the previous result of the different $\mathbf{y}_i$ which ultimately yields to the resullt for the multivariate case:
\begin{align*}
  \mathbf{W}_\text{ML} &= \Phi^\dagger \mathbf{y}_1 + \ldots + \Phi^\dagger \mathbf{y}_m \\
  &= \sum_{i=1}^m \Phi^\dagger \mathbf{y}_i \\
  &= \Phi^\dagger \sum_{i=1}^m \mathbf{y}_i \\
  &= \Phi^\dagger \mathbf{Y}
\end{align*}
%
\Topic{Comparison of linear regression models}
%
\Problem{5}
%
%
\Topic{Programming Task}
%
\Problem{6}
%
\includepdf[pages=-]{exercise_04_notebook.pdf}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% !!! HOMEWORK ENDS HERE !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../Ressources/Appendix.tex} % !!! DON'T TOUCH !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
