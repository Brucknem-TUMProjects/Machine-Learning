{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgWURGohjfQa"
   },
   "source": [
    "# Programming task 11: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNPxT59TjfQj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyjhGP_bjfQy"
   },
   "source": [
    "## Exporting the results to PDF\n",
    "Once you complete the assignments, export the entire notebook as PDF and attach it to your homework solutions. \n",
    "The best way of doing that is\n",
    "1. Run all the cells of the notebook.\n",
    "2. Export/download the notebook as PDF (File -> Download as -> PDF via LaTeX (.pdf)).\n",
    "3. Concatenate your solutions for other tasks with the output of Step 2. On a Linux machine you can simply use `pdfunite`, there are similar tools for other platforms too. You can only upload a single PDF file to Moodle.\n",
    "\n",
    "Make sure you are using `nbconvert` Version 5.5 or later by running `jupyter nbconvert --version`. Older versions clip lines that exceed page width, which makes your code harder to grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jefJM-p-jfQ_"
   },
   "source": [
    "##  PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S67V01EKjfRC"
   },
   "source": [
    "Given the data in the matrix X your tasks is to:\n",
    "* Calculate the covariance matrix $\\Sigma$.\n",
    "* Calculate eigenvalues and eigenvectors of $\\Sigma$.\n",
    "* Plot the original data $X$ and the eigenvectors to a single diagram. What do you observe? Which eigenvector corresponds to the smallest eigenvalue?\n",
    "* Determine the smallest eigenvalue and remove its corresponding eigenvector. The remaining eigenvector is the basis of a new subspace.\n",
    "* Transform all vectors in X in this new subspace by expressing all vectors in X in this new basis.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgG2AvhtjfRH"
   },
   "source": [
    "### The given data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-o-k-FKQjfRK"
   },
   "outputs": [],
   "source": [
    "X = np.array([(-3,-2),(-2,-1),(-1,0),(0,1),\n",
    "              (1,2),(2,3),(-2,-2),(-1,-1),\n",
    "              (0,0),(1,1),(2,2), (-2,-3),\n",
    "              (-1,-2),(0,-1),(1,0), (2,1),(3,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cJFP_AIjfRR"
   },
   "source": [
    "### Task 1: Calculate the covariance matrix $\\Sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "DW5stWoVjfRU",
    "outputId": "8cf9d502-9219-418d-ee71-80003d86aa38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X before transformation: \n",
      "(17, 2)\n",
      "[[-3 -2]\n",
      " [-2 -1]\n",
      " [-1  0]\n",
      " [ 0  1]\n",
      " [ 1  2]\n",
      " [ 2  3]\n",
      " [-2 -2]\n",
      " [-1 -1]\n",
      " [ 0  0]\n",
      " [ 1  1]\n",
      " [ 2  2]\n",
      " [-2 -3]\n",
      " [-1 -2]\n",
      " [ 0 -1]\n",
      " [ 1  0]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n",
      "\n",
      "Covariance matrix: \n",
      "[[3.    2.625]\n",
      " [2.625 3.   ]]\n"
     ]
    }
   ],
   "source": [
    "def get_covariance(X):\n",
    "    \"\"\"Calculates the covariance matrix of the input data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        Data matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Sigma : array, shape [D, D]\n",
    "        Covariance matrix\n",
    "        \n",
    "    \"\"\"\n",
    "    return np.cov(X, rowvar=False)\n",
    "\n",
    "print(\"X before transformation: \")\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "print(\"Covariance matrix: \")\n",
    "print(get_covariance(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWSBVcQcjfRd"
   },
   "source": [
    "### Task 2: Calculate eigenvalues and eigenvectors of  $\\Sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "KqkraRaYjfRf",
    "outputId": "1abc6e4e-d2f6-4556-916f-010f5a92c032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X before transformation: \n",
      "(17, 2)\n",
      "[[-3 -2]\n",
      " [-2 -1]\n",
      " [-1  0]\n",
      " [ 0  1]\n",
      " [ 1  2]\n",
      " [ 2  3]\n",
      " [-2 -2]\n",
      " [-1 -1]\n",
      " [ 0  0]\n",
      " [ 1  1]\n",
      " [ 2  2]\n",
      " [-2 -3]\n",
      " [-1 -2]\n",
      " [ 0 -1]\n",
      " [ 1  0]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n",
      "\n",
      "Eigenvalues and Eigenvectors: \n",
      "(array([5.625, 0.375]), array([[ 0.70710678, -0.70710678],\n",
      "       [ 0.70710678,  0.70710678]]))\n"
     ]
    }
   ],
   "source": [
    "def get_eigen(S):\n",
    "    \"\"\"Calculates the eigenvalues and eigenvectors of the input matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array, shape [D, D]\n",
    "        Square symmetric positive definite matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    L : array, shape [D]\n",
    "        Eigenvalues of S\n",
    "    U : array, shape [D, D]\n",
    "        Eigenvectors of S\n",
    "    \n",
    "    \"\"\"\n",
    "    return np.linalg.eig(S)\n",
    "print(\"X before transformation: \")\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "print(\"Eigenvalues and Eigenvectors: \")\n",
    "print(get_eigen(get_covariance(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRcfOhfwjfRm"
   },
   "source": [
    "### Task 3: Plot the original data X and the eigenvectors to a single diagram.\n",
    "\n",
    "Note that, in general if $u_i$ is an eigenvector of the matrix $M$ with eigenvalue $\\lambda_i$ then $\\alpha \\cdot u_i$ is also an eigenvector of $M$ with the same eigenvalue $\\lambda_i$, where $\\alpha$ is an arbitrary scalar (including $\\alpha=-1$). \n",
    "\n",
    "Thus, the signs of the eigenvectors are arbitrary, and you can flip them without changing the meaning of the result. Only their direction matters. The particular result depends on the algorithm used to find them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "id": "5mTe-7ZwjfRp",
    "outputId": "d62122f5-3f8d-4b3e-fd30-48a2919db6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: \n",
      "[5.625 0.375]\n",
      "\n",
      "U: \n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "\n",
      "U L U^{T}\n",
      "[[3.    2.625]\n",
      " [2.625 3.   ]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhTPIJalw/wHvvnqp8VafNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the original data\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "\n",
    "# plot the mean of the data\n",
    "mean_d1, mean_d2 = X.mean(0)\n",
    "plt.plot(mean_d1, mean_d2, 'o', markersize=10, color='red', alpha=0.5)\n",
    "\n",
    "# calculate the covariance matrix\n",
    "Sigma = get_covariance(X)\n",
    "# calculate the eigenvector and eigenvalues of Sigma\n",
    "L, U = get_eigen(Sigma)\n",
    "\n",
    "print(\"L: \")\n",
    "print(L)\n",
    "print()\n",
    "\n",
    "print(\"U: \")\n",
    "print(U)\n",
    "print()\n",
    "\n",
    "print(\"U L U^{T}\")\n",
    "print((U.dot(np.diag(L)).dot(U.T)))\n",
    "print()\n",
    "\n",
    "plt.arrow(mean_d1, mean_d2, U[0, 0], U[1, 0], width=0.01, color='red', alpha=0.5)\n",
    "plt.arrow(mean_d1, mean_d2, U[0, 1], U[1, 1], width=0.01, color='red', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gEuT12hKjfRy"
   },
   "source": [
    "What do you observe in the above plot? Which eigenvector corresponds to the smallest eigenvalue?\n",
    "\n",
    "Write your answer here:\n",
    "\n",
    "[ 0.70710678, -0.70710678]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onL1cs5JjfR1"
   },
   "source": [
    "### Task 4: Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L74gWcrrjfR3"
   },
   "source": [
    "Determine the smallest eigenvalue and remove its corresponding eigenvector. The remaining eigenvector is the basis of a new subspace. Transform all vectors in X in this new subspace by expressing all vectors in X in this new basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amP7vLozjfR6"
   },
   "outputs": [],
   "source": [
    "def transform(X, U, L):\n",
    "    \"\"\"Transforms the data in the new subspace spanned by the eigenvector corresponding to the largest eigenvalue.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        Data matrix.\n",
    "    L : array, shape [D]\n",
    "        Eigenvalues of Sigma_X\n",
    "    U : array, shape [D, D]\n",
    "        Eigenvectors of Sigma_X\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_t : array, shape [N, 1]\n",
    "        Transformed data\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"L before transformation: \")\n",
    "    print(np.diag(L))\n",
    "    print()\n",
    "\n",
    "    print(\"U before transformation: \")\n",
    "    print(U)\n",
    "    print()\n",
    "\n",
    "    idx = np.argsort(L)[::-1]\n",
    "    U = U[:,idx]\n",
    "    L = L[idx[:-1]]\n",
    "    U = U[:, :-1]\n",
    "\n",
    "    print(\"L after transformation: \")\n",
    "    print(L)\n",
    "    print()\n",
    "\n",
    "    print(\"U after transformation: \")\n",
    "    print(U)\n",
    "    print()\n",
    "\n",
    "    print(\"X before transformation: \")\n",
    "    print(X.shape)\n",
    "    print(X)\n",
    "    print()\n",
    "    \n",
    "    print(\"X after transformation: \")\n",
    "    print(X.dot(U).shape)\n",
    "    print(X.dot(U))\n",
    "    print()\n",
    "\n",
    "    return X.dot(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "65L4uNbEjfSA",
    "outputId": "488ad35d-fc3d-42eb-ba04-657841da7be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L before transformation: \n",
      "[[5.625 0.   ]\n",
      " [0.    0.375]]\n",
      "\n",
      "U before transformation: \n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "\n",
      "L after transformation: \n",
      "[5.625]\n",
      "\n",
      "U after transformation: \n",
      "[[0.70710678]\n",
      " [0.70710678]]\n",
      "\n",
      "X before transformation: \n",
      "(17, 2)\n",
      "[[-3 -2]\n",
      " [-2 -1]\n",
      " [-1  0]\n",
      " [ 0  1]\n",
      " [ 1  2]\n",
      " [ 2  3]\n",
      " [-2 -2]\n",
      " [-1 -1]\n",
      " [ 0  0]\n",
      " [ 1  1]\n",
      " [ 2  2]\n",
      " [-2 -3]\n",
      " [-1 -2]\n",
      " [ 0 -1]\n",
      " [ 1  0]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n",
      "\n",
      "X after transformation: \n",
      "(17, 1)\n",
      "[[-3.53553391]\n",
      " [-2.12132034]\n",
      " [-0.70710678]\n",
      " [ 0.70710678]\n",
      " [ 2.12132034]\n",
      " [ 3.53553391]\n",
      " [-2.82842712]\n",
      " [-1.41421356]\n",
      " [ 0.        ]\n",
      " [ 1.41421356]\n",
      " [ 2.82842712]\n",
      " [-3.53553391]\n",
      " [-2.12132034]\n",
      " [-0.70710678]\n",
      " [ 0.70710678]\n",
      " [ 2.12132034]\n",
      " [ 3.53553391]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_t = transform(X, U, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-A-t3Ej8jfSK"
   },
   "source": [
    "##  SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eYgbiYSjfSM"
   },
   "source": [
    "### Task 5: Given the matrix $M$ find its SVD decomposition $M= U \\cdot \\Sigma \\cdot V$ and reduce it to one dimension using the approach described in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFQWbwPwjfSO"
   },
   "outputs": [],
   "source": [
    "M = np.array([[1, 2], [6, 3],[0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J23aOMRNjfST"
   },
   "outputs": [],
   "source": [
    "def reduce_to_one_dimension(M):\n",
    "    \"\"\"Reduces the input matrix to one dimension using its SVD decomposition.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M : array, shape [N, D]\n",
    "        Input matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    M_t: array, shape [N, 1]\n",
    "        Reduce matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    u, s, vh = np.linalg.svd(M, full_matrices=True)\n",
    "    print(\"M before transformation: \")\n",
    "    print(M.shape)\n",
    "    print(M)\n",
    "    print()\n",
    "\n",
    "    print(\"U matrix before transformation: \")\n",
    "    print(u.shape)\n",
    "    print(u)\n",
    "    print()\n",
    "\n",
    "    print(\"Sigma matrix before transformation: \")\n",
    "    print(s.shape)\n",
    "    print(s)\n",
    "    print()\n",
    "\n",
    "    print(\"V matrix before transformation: \")\n",
    "    print(vh.shape)\n",
    "    print(vh)\n",
    "    print()\n",
    "\n",
    "    idx = np.argsort(s)[::-1]\n",
    "    s = s[idx[0]]\n",
    "    u = u[:,idx[0]]\n",
    "    vh = vh[:,idx[0]]\n",
    "    u = u[:,np.newaxis]\n",
    "    vh = vh[:, np.newaxis]\n",
    "\n",
    "    print(\"U matrix after transformation: \")\n",
    "    print(u.shape)\n",
    "    print(u)\n",
    "    print()\n",
    "\n",
    "    print(\"Sigma matrix after transformation: \")\n",
    "    print(s.shape)\n",
    "    print(s)\n",
    "    print()\n",
    "\n",
    "    print(\"V matrix after transformation: \")\n",
    "    print(vh.shape)\n",
    "    print(vh)\n",
    "    print()\n",
    "\n",
    "    result = (u * s).dot(vh.T)\n",
    "    print(\"M after transformation: \")\n",
    "    print(M.shape)\n",
    "    print(result)\n",
    "    print()\n",
    "    print(\"Matrix rank of M after transformation: \")\n",
    "    print(np.linalg.matrix_rank(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "id": "wWrMKC7YjfSa",
    "outputId": "9eb649ed-124a-46f5-f2e9-c53a9c59586b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M before transformation: \n",
      "(3, 2)\n",
      "[[1 2]\n",
      " [6 3]\n",
      " [0 2]]\n",
      "\n",
      "U matrix before transformation: \n",
      "(3, 3)\n",
      "[[-0.27073584  0.54578489 -0.79298232]\n",
      " [-0.95094914 -0.27969357  0.13216372]\n",
      " [-0.14965909  0.78986731  0.59473674]]\n",
      "\n",
      "Sigma matrix before transformation: \n",
      "(2,)\n",
      "[7.02571561 2.15390813]\n",
      "\n",
      "V matrix before transformation: \n",
      "(2, 2)\n",
      "[[-0.85065081 -0.52573111]\n",
      " [-0.52573111  0.85065081]]\n",
      "\n",
      "U matrix after transformation: \n",
      "(3, 1)\n",
      "[[-0.27073584]\n",
      " [-0.95094914]\n",
      " [-0.14965909]]\n",
      "\n",
      "Sigma matrix after transformation: \n",
      "()\n",
      "7.025715605900788\n",
      "\n",
      "V matrix after transformation: \n",
      "(2, 1)\n",
      "[[-0.85065081]\n",
      " [-0.52573111]]\n",
      "\n",
      "M after transformation: \n",
      "(3, 2)\n",
      "[[1.61803399 1.        ]\n",
      " [5.68328157 3.51246118]\n",
      " [0.89442719 0.5527864 ]]\n",
      "\n",
      "Matrix rank of M after transformation: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "M_t = reduce_to_one_dimension(M)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "exercise_11_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
