%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../Ressources/Preamble.tex} % !!! DON'T TOUCH !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\ExerciseNumber}{01}

\newcommand{\PersonOne}{Marcel Bruckner (03674122)}
\newcommand{\PersonTwo}{Julian Hohenadel (03673879)}
\newcommand{\PersonThree}{Kevin Bein (03707775)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOKUMENT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../Ressources/Cover.tex} % !!! DON'T TOUCH !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% !!! HOMEWORK STARTS HERE !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\Topic{Linear Classification}
%
\Problem{1}
%
\begin{flushleft}
a) It must be Bernoulli because it is a binary classification model. $y$ can only become $0$ or $1$.
\end{flushleft}
\begin{flushleft}
b) For a $x$ to be classified as $1$ the probability of $p(y=1|x)$ must be greater than the probability of $p(y=0|x)$ which is equal to $\log \frac{p(y=1|x)}{p(y=0|x)} > 0$.
\end{flushleft}
\begin{align*}
  \log \frac{p(y=1|x)}{p(y=0|x)} &= \log \frac{p(x|y=1)\cdot p(y=1)}{p(x|y=0)\cdot p(y=0)} \\
  &= \log \frac{p(x|y=1)\cdot \frac{1}{2}}{p(x|y=0)\cdot \frac{1}{2}} \\
  &= \log \frac{p(x|y=1)}{p(x|y=0)} \\
  &= \log \frac{\lambda_1 \exp(-\lambda_1 x)}{\lambda_0 \exp(-\lambda_0 x)} \\
  &= \log \frac{\lambda_1}{\lambda_0} + \lambda_0 x - \lambda_1x \\
  &= (\log(\lambda_1) - \log(\lambda_0)) + (\lambda_0 - \lambda_1)x \\
  &\Rightarrow (\lambda_0 - \lambda_1)x > \log(\lambda_1) - \log(\lambda_0) \\
  &\Rightarrow x > \frac{\log(\lambda_1) - \log(\lambda_0)}{\lambda_0 - \lambda_1}
\end{align*}
\begin{flushleft}
For $\lambda_0 > \lambda_1$, $x$ must be bigger than $\frac{\log(\lambda_0) - \log(\lambda_1)}{\lambda_0 - \lambda_1}$. In the other case where $\lambda_1 > \lambda_0$, $x$ must be bigger or equal to 0 but smaller than $\frac{\log(\lambda_0) - \log(\lambda_1)}{\lambda_0 - \lambda_1}$.
\end{flushleft}
%
%
\Problem{2}
%
%
\Problem{3}
\begin{flushleft}
Softmax $\sigma_\text{soft}(x) = \frac{\exp(x_i)}{\sum_{i=1}^C \exp(x_k)}$
and Sigmoid $\sigma_\text{sig} = \frac{1}{1+\exp(-a)}$. For $C = \{1,2\}$ we show that $\sigma_\text{soft} \overset{!}{=} \sigma_\text{sig}$.
\end{flushleft}
\begin{align*}
  \sigma_\text{soft}(a) &= \frac{\exp(w_1^T x)}{\sum_{i=1}^C \exp(w_i^T x)} \\
  &= \frac{\exp(w_1^T x)}{\exp(w_1^T x) \exp(w_2^T x)} \\
  &= \frac{1}{1+ \exp(w_1^T x) / \exp(w_2^T x)} \\
  &= \frac{1}{1+ \exp(w_1^T x - w_2^T x)} \\
  &= \frac{1}{1+ \exp(-(w_2 - w_1)^T x)} \\
  &= \sigma_\text{sig}(\bar{w}^T x) \\
  &= \sigma_\text{sig}(a)
\end{align*}
%
%
\Problem{4}
\begin{flushleft}
Similar to to the lecture, we need to map to a different space. For example, simply determining in which quadrant a point is located in, is sufficient. 
\end{flushleft}
\[
\phi(x_1, x_2) = 
  \begin{cases} 
    0 & \text{if } x_1 < 0, x_2 > 0 \text{ or } x_1 > 0, x_2 < 0 \\
    1 & \text{else}
  \end{cases}
\]
\begin{flushleft}
($0$ if $x$ is the top right or bottom left quadrant and $1$ otherwise)
\end{flushleft}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% !!! HOMEWORK ENDS HERE !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{../Ressources/Appendix.tex} % !!! DON'T TOUCH !!!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
